# AI 简报 2025-08-21 → 2025-08-28（JST）

## Hacker News

- **AI 工具需在贡献中披露**[news.ycombinator.com](https://news.ycombinator.com/item?id=44976568#:~:text=AI tooling must be disclosed,12)。HashiCorp 联合创始人 Mitchell Hashimoto 提交的提案要求开源项目贡献者披露是否使用了 AI 辅助工具生成代码，以便维护者决定审核力度[github.com](https://github.com/ghostty-org/ghostty/pull/8289#:~:text=I think%2C at this stage,common courtesy to disclose this)[github.com](https://github.com/ghostty-org/ghostty/pull/8289#:~:text=The disclosure is to help,trick me into doing so)。该提案已合并进 Ghostty 项目，引发热议，支持者认为 AI 生成代码存在潜在授权和质量风险，需要透明度[github.com](https://github.com/ghostty-org/ghostty/pull/8289#:~:text=478 LennyPenny%2C barscn%2C krono%2C ethanniser%2C,more reacted with heart emoji)。（HN积分: 724分，评论: 461条）
- **使用 LLM 编码代理的软件开发体验（第二部分）**[news.ycombinator.com](https://news.ycombinator.com/item?id=44991884#:~:text=My experience creating software with,12)。一位开发者分享了利用 AI 编码助手进行项目开发的经验和技巧。他强调使用 AI 代理是一种“创作”而不仅是编程，并提供了提高产出的技巧，如使用 Anthropic Claude（Claude Sonnets 模型）处理复杂编码任务、为模型提供充分上下文、选择合适的计费方案等[efitz-thoughts.blogspot.com](https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html#:~:text=,just a hobbyist with aspirations)[efitz-thoughts.blogspot.com](https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html#:~:text=,Roo Code at this time)。作者通过良好地管理上下文（如在项目中建立context/目录供AI引用）等方法，大幅提升了编码效率[efitz-thoughts.blogspot.com](https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html#:~:text=Context “Context” refers to the,to the model if needed)[efitz-thoughts.blogspot.com](https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html#:~:text=How the agent gets additional,with only a single approval)。（HN积分: 189分，评论: 103条）
- **通过性能-效率优化路由让 LLM 更便宜更强**[news.ycombinator.com](https://news.ycombinator.com/item?id=44985278#:~:text=Making LLMs Cheaper and Better,12)。这是一篇来自 arXiv 的论文 *Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing*，提出了“Avengers-Pro”框架：在推理时将查询动态分配给不同容量的模型，以平衡成本和性能[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=,pro%2C and Claude)[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=opus,available at this https URL)。在6个基准上，Avengers-Pro 通过调整性能-效率参数，能以**降低63%推理成本**的代价达到单一最强模型 ~90%的性能，或在相同成本下将精度提高7%[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=model based on a performance,Code is)。论文称该方法在任意给定成本/精度下都能形成帕累托最优解，并已开源代码供验证[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=opus,available at this https URL)。（HN积分: 129分，评论: 28条）

## Reddit 📰

**r/MachineLearning**（机器学习）

- **[P] <80行代码实现语言扩散模型**[reddit.com](https://www.reddit.com/r/MachineLearning/#:~:text=•  ,can view the project at)。一位用户分享项目，复现了论文《Large Language Diffusion Models》的部分成果。他使用不到80行Python代码构建扩散式语言模型，将DistilBERT在TinyStories数据集上微调，通过反向扩散过程生成简短故事[reddit.com](https://www.reddit.com/r/MachineLearning/#:~:text=•  ,can view the project at)。结果超出预期，证明简化的扩散模型也能产生有意义的文本输出。（Reddit得票: 320+，日期: 2025/08/25） *标签*: LLM, Diffusion, NLP, 项目

**r/LocalLLaMA**（本地大模型）

- **Qwen3-Coder 发布！**[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=We’re releasing Qwen3,Verified)。阿里巴巴开源社区推出了新一代代码大型模型 **Qwen3-Coder-480B-A35B-Instruct**，总参数4800亿（Mixture-of-Experts 架构，每次激活35亿参数），原生支持256K上下文（可拓展至百万级）[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=We’re releasing Qwen3,Verified)。这是迄今最强的开源“代理式”代码模型，在多项代码Agent基准上达到顶尖水准[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=We’re releasing Qwen3,Verified)。同时开源的还有命令行工具 **Qwen Code**，包含定制提示和函数调用协议，充分发挥 Qwen3-Coder 的自主编程能力[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=Alongside the model%2C we're also,Agentic Coding in the World)。（Reddit得票: 799，日期: 2025/08/24） *标签*: 开源, LLM, 代码代理

**r/Artificial**（通用人工智能）

- **Musk 的 Grok 聊天机器人出现气候否认倾向**[scientificamerican.com](https://www.scientificamerican.com/article/elon-musks-ai-chatbot-grok-is-reciting-climate-denial-talking-points/#:~:text=,on perspective%2C geography%2C and timeframe)[scientificamerican.com](https://www.scientificamerican.com/article/elon-musks-ai-chatbot-grok-is-reciting-climate-denial-talking-points/#:~:text=“Grok was criticized for progressive,”)。社区讨论发现，Elon Musk 的 xAI 公司开发的 **Grok** 聊天机器人在被问及气候变化威胁时，给出了不同于 ChatGPT 等模型的回答——它先引用NASA/NOAA数据承认风险，又加入气候怀疑论者语调，淡化紧迫性[scientificamerican.com](https://www.scientificamerican.com/article/elon-musks-ai-chatbot-grok-is-reciting-climate-denial-talking-points/#:~:text=,on perspective%2C geography%2C and timeframe)。Grok 表示此改变是由于 Musk 要求使回复“政治中立”，在平衡主流观点时放大了少数派的怀疑论[scientificamerican.com](https://www.scientificamerican.com/article/elon-musks-ai-chatbot-grok-is-reciting-climate-denial-talking-points/#:~:text=“Grok was criticized for progressive,”)。这一现象引发担忧：AI 答复易受制作者偏见影响，可能传播误导信息。（Reddit得票: 5.4k，评论: 151条） *标签*: AI偏见, 聊天机器人, 气候变化

## Hugging Face Forums

- **极简 AI 代理库 “smolagents”**[discuss.huggingface.co](https://discuss.huggingface.co/t/new-framework-smolagents/135421#:~:text=New Framework smolagents ,tools and orchestrate other agents)。在 Hugging Face 论坛上，社区讨论了一款新发布的轻量级代理框架 **smolagents**。该库让大型语言模型代理“边写代码边执行”：通过让 LLM 自动编写和运行 Python 代码来调用工具、协调子代理等[discuss.huggingface.co](https://discuss.huggingface.co/t/new-framework-smolagents/135421#:~:text=New Framework smolagents ,tools and orchestrate other agents)。开发者演示了如何用几行代码构建一个简易AI代理，从而为**自动化工作流**提供一个极简、可扩展的方案。（帖子活跃度: 多位用户讨论，发布日期: 2025/08/22） *标签*: 开发库, AI代理, 自动化

## 公司动态

**OpenAI** 🔮

- **“模型规范”公众意见调查**[openai.com](https://openai.com/index/collective-alignment-aug-2025-updates/#:~:text=We surveyed over 1%2C000 people,adopted changes from the disagreements)[openai.com](https://openai.com/index/collective-alignment-aug-2025-updates/#:~:text=Today%2C we share a few,to enable future work in)。OpenAI 公布了一项 **集体对齐 (Collective Alignment)** 研究结果：他们调查了全球1000多名用户对于AI行为准则（Model Spec）的看法[openai.com](https://openai.com/index/collective-alignment-aug-2025-updates/#:~:text=We surveyed over 1%2C000 people,adopted changes from the disagreements)。结果显示大部分公众偏好与现有规范一致，但也有分歧之处。OpenAI 已据此**更新模型规范**：澄清一些模棱两可的措辞，并针对公众普遍关注的原则进行调整[openai.com](https://openai.com/index/collective-alignment-aug-2025-updates/#:~:text=Today%2C we share a few,to enable future work in)。这一过程体现了 OpenAI 希望将多元价值观纳入 AI 默认行为的努力，相关匿名数据集也已公开以供研究[openai.com](https://openai.com/index/collective-alignment-aug-2025-updates/#:~:text=Today%2C we share a few,to enable future work in)。（发布日期: 2025-08-27） *标签*: 对齐, 规范, 调研
- **OpenAI 与 Anthropic 安全评估联测**[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=This summer%2C OpenAI and Anthropic,gaps that might otherwise be)[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=In this post%2C we share,models on all the evaluations)。OpenAI 和 Anthropic 首次合作进行了**跨模型内部安全测试**[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=This summer%2C OpenAI and Anthropic,gaps that might otherwise be)：双方互相用自己的内部对抗性评估，对对方的新模型进行测试，并公开了结果。OpenAI 在报告中比较了 Anthropic 的 Claude Opus 4/Sonnet 4 与自家的 GPT-4o/4.1 等聊天模型在抗提示绕过、幻觉、滥用抵抗等方面的表现[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=In this post%2C we share,models on all the evaluations)。结果显示 GPT-5 在奉承、幻觉、防滥用等方面有显著改进[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=to ensure that each lab’s,issues of safety and alignment)。双方认为这种透明评估有助于发现安全薄弱点，并呼吁业界合力持续改进 AI 对齐安全，因为模型行为可被快速干预和改变[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=substantial improvements in areas like,issues of safety and alignment)[openai.com](https://openai.com/index/openai-anthropic-safety-evaluation/#:~:text=)。（发布日期: 2025-08-27） *标签*: AI安全, 对齐, 合作

**Google** 🌐

- **（无重大更新）** 本周谷歌未有与 LLM或 AI Agent 密切相关的官方博客发布。 *（如有最新消息，将在此板块呈现）*

**Anthropic** 🤖

- **AI 威胁情报报告揭示滥用案例**[anthropic.com](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025#:~:text=Our Threat Intelligence report discusses,detect and counter these abuses)[anthropic.com](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025#:~:text=,creating false identities allowing fraud)。Anthropic 发布8月安全报告，详述最近检测到的若干 **Claude 模型被恶意滥用** 案例[anthropic.com](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025#:~:text=Our Threat Intelligence report discusses,detect and counter these abuses)。其中包括黑客利用 Claude Code 执行大规模数据盗窃和敲诈、朝鲜黑客用 AI 招聘诈骗、以及低技术门槛的犯罪分子用 Claude 生成勒索软件等[anthropic.com](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025#:~:text=recent examples of Claude being,detect and counter these abuses)[anthropic.com](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025#:~:text=sophisticated cyberattacks%2C not just advise,reach to more potential targets)。报告发现**“Agentic AI”已被不法分子武器化**：LLM 自动化工具降低了网络犯罪门槛，让非专业黑客也能发动复杂攻击[anthropic.com](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025#:~:text=,creating false identities allowing fraud)。Anthropic 描述了已采取的检测和对策，并警告威胁行为者在不断探索绕过AI安全措施的新手段。（发布日期: 2025-08-27） *标签*: 安全, 滥用, 网络安全

**Microsoft** 💼

- **（无更新）** 截至窗口期，微软官方未发布新的 LLM/AI Agent 相关动态。

**Alibaba 阿里** 🇨🇳

- **阿里巴巴推出 Qwen3 模型家族**[alibabacloud.com](https://www.alibabacloud.com/blog/alibaba-unveils-new-qwen3-models-for-coding-complexing-reasoning-and-machine-translation_602415#:~:text=Built upon a Mixture,only 35 billion per token)[alibabacloud.com](https://www.alibabacloud.com/blog/alibaba-unveils-new-qwen3-models-for-coding-complexing-reasoning-and-machine-translation_602415#:~:text=With the release of the,more inclusively than ever before)。阿里云社区公布了第三代通义系列模型 “Qwen3”，包括大规模代码模型 **Qwen3-Coder**、超大推理模型 **Qwen3-235B-Thinking** 以及升级的 **Qwen-MT 翻译模型**。其中 Qwen3-Coder 采用4800亿参数 MoE 架构，每次调用35亿参数，支持256K扩展至百万长上下文，用于“自主编程”，在代码代理任务上达到开源SOTA[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=We’re releasing Qwen3,Verified)。Qwen3-235B-Thinking 则专注复杂推理，扩展了“思维链”长度，在数学、科学等高难度任务上取得开源最佳结果[alibabacloud.com](https://www.alibabacloud.com/blog/alibaba-unveils-new-qwen3-models-for-coding-complexing-reasoning-and-machine-translation_602415#:~:text=Alibaba also introduced Qwen3,for highly complex reasoning tasks)。新版 Qwen-MT 支持92种语言翻译，利用MoE架构提升通用性和效率[alibabacloud.com](https://www.alibabacloud.com/blog/alibaba-unveils-new-qwen3-models-for-coding-complexing-reasoning-and-machine-translation_602415#:~:text=Qwen,Supporting 92 Languages)[alibabacloud.com](https://www.alibabacloud.com/blog/alibaba-unveils-new-qwen3-models-for-coding-complexing-reasoning-and-machine-translation_602415#:~:text=Qwen,times and reduced API costs)。所有模型均开源发布（Apache 2.0），彰显阿里在开放AI领域的领先地位[alibabacloud.com](https://www.alibabacloud.com/blog/alibaba-unveils-new-qwen3-models-for-coding-complexing-reasoning-and-machine-translation_602415#:~:text=With the release of the,more inclusively than ever before)。（发布日期: 2025-08-08） *标签*: 开源, 大模型, 通义

**Tencent 腾讯** 🇨🇳

- **（无重大更新）** 本周暂无腾讯相关 LLM/AI Agent 重要发布动态。

## Medium / Towards Data Science

- **将 LLM 作为“裁判”的自动评估指南**（作者: Dr. Owns）[dsssolutions.com](https://dsssolutions.com/2025/08/13/how-to-use-llms-for-powerful-automatic-evaluations/#:~:text=The post How to Use,first on Towards Data Science)。一篇科普文章介绍了如何用**大型语言模型执行自动化评估**。作者提出 *“LLM-as-a-Judge”* 概念，让模型对其他模型生成的文本进行评分，替代人工标注[dsssolutions.com](https://dsssolutions.com/2025/08/13/how-to-use-llms-for-powerful-automatic-evaluations/#:~:text=The post How to Use,first on Towards Data Science)。文章通过易懂案例展示 LLM 自动评估摘要的流程，并讨论这种无参考评估方法的准确性和局限。（发布: 2025-08-13）*标签*: LLM评估, 自动化, NLP
- **2025年数据科学家如何使用 AI 代理**（作者: Natassha Selvaraj）[kdnuggets.com](https://www.kdnuggets.com/how-i-use-ai-agents-as-a-data-scientist-in-2025#:~:text=And why data scientists must,before manual analysis becomes obsolete)[kdnuggets.com](https://www.kdnuggets.com/how-i-use-ai-agents-as-a-data-scientist-in-2025#:~:text=Recently%2C I have started incorporating,into my data science workflows)。文章描述了一位资深数据科学家借助 AI Agent 提高工作效率的实践。作者列举日常数据科学流程（构建SQL管道、统计分析、A/B实验等）[kdnuggets.com](https://www.kdnuggets.com/how-i-use-ai-agents-as-a-data-scientist-in-2025#:~:text=As data scientists%2C we wear,single workday%2C I have to)[kdnuggets.com](https://www.kdnuggets.com/how-i-use-ai-agents-as-a-data-scientist-in-2025#:~:text=Companies can run up to,automate it using AI agents)中哪些步骤已用 AI 代理自动化，例如用代理执行探索性数据分析、运行统计检验并生成决策建议等[kdnuggets.com](https://www.kdnuggets.com/how-i-use-ai-agents-as-a-data-scientist-in-2025#:~:text=When this process is automated,lifting that we typically do)。通过使用如 Cursor 编辑器等工具，AI 代理能够自主获取数据并完成实验分析，将原需几天的人工作业压缩到更短时间[kdnuggets.com](https://www.kdnuggets.com/how-i-use-ai-agents-as-a-data-scientist-in-2025#:~:text=When this process is automated,lifting that we typically do)。作者呼吁数据科学家尽快掌握 AI 代理技能，以免在 AI 普及后手动分析变得过时。（发布: 2025-08-15）*标签*: 数据科学, 自动化, AI助手

## arXiv 最新论文

- **“GPT-5+”路上的多专家路由架构**[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=,pro%2C and Claude)[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=opus,available at this https URL)。论文 *《Beyond GPT-5: Performance-Efficiency Optimized Routing》*（2025.08.18提交）提出通过**测试时路由**实现LLM性能与成本的折中优化。框架 Avengers-Pro 将不同规模的模型组成集成，根据查询特征自动路由到最合适的模型，从而在无需微调的情况下实现按需调配算力[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=,pro%2C and Claude)。实验证明，在相同预算下该方法比单一最优模型平均准确率提高7%，或在保持性能情况下成本降低27%～63%[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=model based on a performance,Code is)。该方法得到了一条涵盖各种成本-精度点的帕累托前沿，并已开放源码[arxiv.org](https://arxiv.org/abs/2508.12631#:~:text=opus,available at this https URL)。*（以上成果在 HN 上获得热议[news.ycombinator.com](https://news.ycombinator.com/item?id=44985278#:~:text=Making LLMs Cheaper and Better,12)）* *标签*: Mixture-of-Experts, 路由, 成本优化

## GitHub 趋势

- **Qwen3 模型与工具代码开源**[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=Alongside the model%2C we're also,Agentic Coding in the World)。阿里通过 **qwen** 仓库 开源了 Qwen3 系列模型及相关工具。其中 Qwen3-Coder 模型权重和推理代码已发布，开发者也可使用 **Qwen Code** CLI 工具来调用模型执行自主编码任务[reddit.com](https://www.reddit.com/r/LocalLLaMA/comments/1m6qdet/qwen3coder_is_here/#:~:text=Alongside the model%2C we're also,Agentic Coding in the World)。这些资源有助于社区在本地复现 Qwen3 的强大能力，打造专属的 AI 编程代理。（GitHub⭐: 新发布） *标签*: 开源模型, 代码库, HuggingFace
- **AgentFly 代码仓库发布**[huggingface.co](https://huggingface.co/papers/trending#:~:text=AgentFly%3A Fine,tuning LLMs)[huggingface.co](https://huggingface.co/papers/trending#:~:text=,11 authors)。NVIDIA 等研究者在 GitHub 上公开了论文 *AgentFly: 无需微调LLM本体的代理微调框架* 对应的实现（见[huggingface.co](https://huggingface.co/papers/trending#:~:text=AgentFly%3A Fine,tuning LLMs)）。AgentFly运用**记忆增强的在线强化学习**策略，让LLM代理通过外部记忆模块持续学习新技能而无需更新底层模型参数[huggingface.co](https://huggingface.co/papers/trending#:~:text=In this paper%2C we introduce,parametric. The)[huggingface.co](https://huggingface.co/papers/trending#:~:text=,11 authors)。该代码仓库提供了模型训练脚本和示例，有助于开发更**自适应的通用 AI 代理**。（GitHub⭐: 600+，发布日期: 2025-08-22） *标签*: 强化学习, 终身学习, 通用代理

## Papers With Code 最新论文及代码

- **AgentFly: 无需微调LLM的代理学习**[huggingface.co](https://huggingface.co/papers/trending#:~:text=AgentFly%3A Fine,tuning LLMs)[huggingface.co](https://huggingface.co/papers/trending#:~:text=,11 authors)。提出一种让 **LLM智能体** 在不改动底层大模型的情况下持续适应的新范式。AgentFly 利用**记忆增强的在线 RL**（Memory-MDP框架），通过神经案例选择策略引用并更新其“记忆库”，实现持续学习[huggingface.co](https://huggingface.co/papers/trending#:~:text=In this paper%2C we introduce,parametric. The)[huggingface.co](https://huggingface.co/papers/trending#:~:text=,11 authors)。在学术助手 GAIA基准上取得首位，DeepResearcher数据集上F1提高近5%，超越需更新模型参数的SOTA方法[huggingface.co](https://huggingface.co/papers/trending#:~:text=rewriting mechanism%2C whereas policy improvement,ended skill)[huggingface.co](https://huggingface.co/papers/trending#:~:text=,11 authors)。代码已开源[huggingface.co](https://huggingface.co/papers/trending#:~:text=without gradient updates%2C advancing machine,Fly%2FAgentFly)。 *标签*: LLM代理, 在线学习, RL
- **M3-Agent: 多模态长时记忆智能体**[huggingface.co](https://huggingface.co/papers/trending#:~:text=We introduce M3,To evaluate memory)[huggingface.co](https://huggingface.co/papers/trending#:~:text=robot) and 929 web,Model%2C code and data are)。字节跳动研究团队发布 **M3-Agent** 框架，让AI代理具备类似人类的**长期记忆**[huggingface.co](https://huggingface.co/papers/trending#:~:text=We introduce M3,To evaluate memory)。M3-Agent 可实时处理视觉和听觉输入，构建情景记忆（episodic）和语义记忆，以实体为中心组织信息，从而更深入理解环境[huggingface.co](https://huggingface.co/papers/trending#:~:text=term memory. Like humans%2C M3,Bench comprises 100)[huggingface.co](https://huggingface.co/papers/trending#:~:text=robot) and 929 web,Model%2C code and data are)。在新引入的长视频问答基准 M3-Bench 上，M3-Agent 经强化学习训练，比使用 Gemini-1.5-pro+GPT-4 提示的基线准确率高5-7个百分点[huggingface.co](https://huggingface.co/papers/trending#:~:text=agent applications%2C such as human,agent)。该工作推动多模态代理朝更类人方向发展，并已开源模型与数据[huggingface.co](https://huggingface.co/papers/trending#:~:text=reinforcement learning%2C outperforms the strongest,Model%2C code and data are)。 *标签*: 多模态, 长期记忆, 增强学习